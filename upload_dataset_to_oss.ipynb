{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14de318-98ab-4e6b-a9dd-bc86ca5fb07a",
   "metadata": {},
   "source": [
    "### Upload HF dataset to OSS\n",
    "\n",
    "Since the size of the dataset can be big, this time we will use a slightly different approach. \n",
    "\n",
    "We're going to use OCI **UploadManager**, with **multipart upload**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3dc478-3ce8-4e25-954d-51179d5a4a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import oci\n",
    "from oci.object_storage import UploadManager\n",
    "from oci.object_storage.transfer.constants import MEBIBYTE\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "# moved namespace to config.py\n",
    "from config import (\n",
    "    NAMESPACE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78eb167f-9a3c-495d-9c04-e252d7937c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the name of the HF dataset (also the dir where it is saved)\n",
    "HF_DIR = \"atco2_hf\"\n",
    "\n",
    "# the bucket where the entire ds will be saved\n",
    "BUCKET = \"atco2_hf\"\n",
    "\n",
    "# config for the UploadManager\n",
    "# for the Upload Manager\n",
    "PART_SIZE = 2 * MEBIBYTE\n",
    "PARALLEL = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3c923b-f579-43da-8a68-46eab86a99a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def progress_callback(bytes_uploaded):\n",
    "    # disabled to avoid thousands of print\n",
    "    # print(\"{} additional bytes uploaded\".format(bytes_uploaded))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd0d5a3-2241-4da4-833e-dabd9441db2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using API Key for auth...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# This code try to get an instance of OCIFileSystem\n",
    "# first try using Resource Principal, otherwise use api keys\n",
    "#\n",
    "try:\n",
    "    rps = oci.auth.signers.get_resource_principals_signer()\n",
    "\n",
    "    # if here, we can use rp\n",
    "    print(\"Using RP for auth...\")\n",
    "\n",
    "    object_storage = oci.object_storage.ObjectStorageClient(config={}, signer=rps)\n",
    "except:\n",
    "    print(\"Using API Key for auth...\")\n",
    "\n",
    "    default_config = oci.config.from_file()\n",
    "\n",
    "    # validate the default config file\n",
    "    oci.config.validate_config(default_config)\n",
    "\n",
    "    object_storage = oci.object_storage.ObjectStorageClient(config=default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9cfe871-f94d-43ca-b014-7d092119361b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy dataset_dict.json to bucket atco2_hf...\n",
      "Copy test/state.json to bucket atco2_hf...\n",
      "Copy test/dataset_info.json to bucket atco2_hf...\n",
      "Copy test/data-00000-of-00001.arrow to bucket atco2_hf...\n",
      "Copy train/state.json to bucket atco2_hf...\n",
      "Copy train/dataset_info.json to bucket atco2_hf...\n",
      "Copy train/data-00000-of-00001.arrow to bucket atco2_hf...\n"
     ]
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(HF_DIR):\n",
    "    for name in files:\n",
    "        orig_path = os.path.join(path, name)\n",
    "\n",
    "        # use_path will be like test/state.json\n",
    "        # remove initial HF_DIR/\n",
    "        use_path = orig_path[len(HF_DIR) + 1 :]\n",
    "        print(f\"Copy {use_path} to bucket {BUCKET}...\")\n",
    "\n",
    "        # copy a single file to bucket\n",
    "        upload_manager = UploadManager(\n",
    "            object_storage, allow_parallel_uploads=True, parallel_process_count=PARALLEL\n",
    "        )\n",
    "\n",
    "        response = upload_manager.upload_file(\n",
    "            NAMESPACE,\n",
    "            BUCKET,\n",
    "            use_path,\n",
    "            orig_path,\n",
    "            part_size=PART_SIZE,\n",
    "            progress_callback=progress_callback,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade31eb1-e8c2-41d5-b0d9-0c47ee4ef716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
