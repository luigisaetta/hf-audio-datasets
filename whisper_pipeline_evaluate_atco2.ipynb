{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b0de75-95d7-4cf4-a7bc-e615963b8aba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate Whisper on ATCO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5eecb-3e7b-46dd-917f-6570cef6e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "# these two file comes from OpenAI Whisper, for text normalization\n",
    "from basic import *\n",
    "from english import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "500e980e-bcc7-4067-9f4b-a849e4e12d40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the metric definition\n",
    "wer = load(\"wer\")\n",
    "\n",
    "# apply the same text normalization rules as Whisper\n",
    "normalizer = EnglishTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a721a874-903a-4cb9-90d5-59720d8c2cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TASK = \"automatic-speech-recognition\"\n",
    "MODEL_LABEL = \"luigisaetta/whisper-atco2-medium\"\n",
    "\n",
    "HF_DIR = \"atco2_hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ad56c9-bf67-4cc7-b3c6-c468e47266b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the dataset from local\n",
    "atco2_hf = load_from_disk(HF_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b717aee-8d14-4031-92ae-80c2b2446af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'sentence'],\n",
       "    num_rows: 56\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test = atco2_hf[\"test\"]\n",
    "\n",
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50c54ee6-7695-40ef-a0d2-05d34927cac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the pipeline and a utility method\n",
    "pipe = pipeline(task=TASK, model=MODEL_LABEL)\n",
    "\n",
    "\n",
    "def transcribe(audio):\n",
    "    text = pipe(audio)[\"text\"]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b05eb-a498-4e5b-900f-fa212fd91fd9",
   "metadata": {},
   "source": [
    "#### Loop all over the test dataset and compute transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff53b7c5-5fc6-4af1-88b2-b8a24489fa46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [09:14<00:00,  9.89s/it]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "expected = []\n",
    "\n",
    "# loop over all test set\n",
    "for row in tqdm(ds_test):\n",
    "    # to get the right WER we neeed to apply same normalization rules as Whisper\n",
    "    # in the local hf dataset text is NOT normalized\n",
    "    expected.append(normalizer(row[\"sentence\"]))\n",
    "\n",
    "    # my Whisper model produces text normalized, since it has been trained on\n",
    "    # luigisaetta/atco2_normalized_augmented ds\n",
    "    text_predicted = transcribe(row[\"audio\"])\n",
    "\n",
    "    predicted.append(normalizer(text_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f78273-c4c7-4088-a1c4-99ba33ba2422",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compute WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce059b83-b300-4c76-91ea-204cc3db6d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER computed on test set is 0.01.\n"
     ]
    }
   ],
   "source": [
    "wer_score = wer.compute(predictions=predicted, references=expected)\n",
    "\n",
    "print(f\"WER computed on test set is {round(wer_score, 2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5f511-bbc7-4d1f-9334-792f97bb968d",
   "metadata": {},
   "source": [
    "On this dataset WER is really good\n",
    "\n",
    "Maybe we're overfitting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400fac0-3700-49c9-8a99-02b8b5980ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
